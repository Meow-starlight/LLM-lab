{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8144822-81bc-4364-820d-c162630fda53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T09:58:51.789678Z",
     "iopub.status.busy": "2024-05-29T09:58:51.789237Z",
     "iopub.status.idle": "2024-05-29T10:00:01.432578Z",
     "shell.execute_reply": "2024-05-29T10:00:01.432001Z",
     "shell.execute_reply.started": "2024-05-29T09:58:51.789657Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正克隆到 'chatglm3-6b'...\n",
      "remote: Enumerating objects: 140, done.\u001b[K\n",
      "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
      "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
      "remote: Total 140 (delta 8), reused 1 (delta 0), pack-reused 122\u001b[K\n",
      "接收对象中: 100% (140/140), 61.16 KiB | 20.39 MiB/s, 完成.\n",
      "处理 delta 中: 100% (60/60), 完成.\n",
      "过滤内容: 100% (15/15), 23.26 GiB | 344.56 MiB/s, 完成.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://www.modelscope.cn/ZhipuAI/chatglm3-6b.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ff349d-e388-44fd-87bf-cfafbdba168a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T10:01:36.271887Z",
     "iopub.status.busy": "2024-05-29T10:01:36.271520Z",
     "iopub.status.idle": "2024-05-29T10:01:40.535558Z",
     "shell.execute_reply": "2024-05-29T10:01:40.534978Z",
     "shell.execute_reply.started": "2024-05-29T10:01:36.271865Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正克隆到 'bge-base-zh-v1.5'...\n",
      "remote: Enumerating objects: 30, done.\u001b[K\n",
      "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
      "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
      "remote: Total 30 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "接收对象中: 100% (30/30), 168.35 KiB | 9.35 MiB/s, 完成.\n",
      "处理 delta 中: 100% (5/5), 完成.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://www.modelscope.cn/AI-ModelScope/bge-base-zh-v1.5.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2f208f7-9ec7-49e4-bc45-5b88ec9b146d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-29T10:35:56.976164Z",
     "iopub.status.busy": "2024-05-29T10:35:56.975835Z",
     "iopub.status.idle": "2024-05-29T10:41:44.980241Z",
     "shell.execute_reply": "2024-05-29T10:41:44.979602Z",
     "shell.execute_reply.started": "2024-05-29T10:35:56.976146Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 18:35:56,978 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: ./bge-base-zh-v1.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create retrieval plugin instance...\n",
      "plugin parameters:  {'embedding_model': './bge-base-zh-v1.5', 'input_path': './sample.jsonl'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 18:35:57,237 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n",
      "2024-05-29 18:35:57,240 - root - INFO - The parsing for the uploaded files is finished.\n",
      "2024-05-29 18:35:57,241 - root - INFO - The format of parsed documents is transferred.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abe18097ecd46c0b4eeb01163629cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 18:35:57,431 - root - INFO - The retriever is successfully built.\n",
      "2024-05-29 18:35:57,459 - transformers_modules.chatglm3_6b.tokenization_chatglm - WARNING - Setting eos_token is not supported, use the default one.\n",
      "2024-05-29 18:35:57,460 - transformers_modules.chatglm3_6b.tokenization_chatglm - WARNING - Setting pad_token is not supported, use the default one.\n",
      "2024-05-29 18:35:57,460 - transformers_modules.chatglm3_6b.tokenization_chatglm - WARNING - Setting unk_token is not supported, use the default one.\n",
      "2024-05-29 18:35:57 [INFO] Applying Weight Only Quantization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ./chatglm3-6b\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17714b8e7f3a4894a78987e96cf34c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 18:36:10 [INFO] Start auto tuning.\n",
      "2024-05-29 18:36:10 [INFO] Quantize model without tuning!\n",
      "2024-05-29 18:36:10 [INFO] Quantize the model with default configuration without evaluating the model.                To perform the tuning process, please either provide an eval_func or provide an                    eval_dataloader an eval_metric.\n",
      "2024-05-29 18:36:10 [INFO] Adaptor has 5 recipes.\n",
      "2024-05-29 18:36:10 [INFO] 0 recipes specified by user.\n",
      "2024-05-29 18:36:10 [INFO] 3 recipes require future tuning.\n",
      "2024-05-29 18:36:10 [INFO] *** Initialize auto tuning\n",
      "2024-05-29 18:36:10 [INFO] {\n",
      "2024-05-29 18:36:10 [INFO]     'PostTrainingQuantConfig': {\n",
      "2024-05-29 18:36:10 [INFO]         'AccuracyCriterion': {\n",
      "2024-05-29 18:36:10 [INFO]             'criterion': 'relative',\n",
      "2024-05-29 18:36:10 [INFO]             'higher_is_better': True,\n",
      "2024-05-29 18:36:10 [INFO]             'tolerable_loss': 0.01,\n",
      "2024-05-29 18:36:10 [INFO]             'absolute': None,\n",
      "2024-05-29 18:36:10 [INFO]             'keys': <bound method AccuracyCriterion.keys of <neural_compressor.config.AccuracyCriterion object at 0x7f92a77f0940>>,\n",
      "2024-05-29 18:36:10 [INFO]             'relative': 0.01\n",
      "2024-05-29 18:36:10 [INFO]         },\n",
      "2024-05-29 18:36:10 [INFO]         'approach': 'post_training_weight_only',\n",
      "2024-05-29 18:36:10 [INFO]         'backend': 'default',\n",
      "2024-05-29 18:36:10 [INFO]         'calibration_sampling_size': [\n",
      "2024-05-29 18:36:10 [INFO]             100\n",
      "2024-05-29 18:36:10 [INFO]         ],\n",
      "2024-05-29 18:36:10 [INFO]         'device': 'cpu',\n",
      "2024-05-29 18:36:10 [INFO]         'diagnosis': False,\n",
      "2024-05-29 18:36:10 [INFO]         'domain': 'auto',\n",
      "2024-05-29 18:36:10 [INFO]         'example_inputs': 'Not printed here due to large size tensors...',\n",
      "2024-05-29 18:36:10 [INFO]         'excluded_precisions': [\n",
      "2024-05-29 18:36:10 [INFO]         ],\n",
      "2024-05-29 18:36:10 [INFO]         'framework': 'pytorch_fx',\n",
      "2024-05-29 18:36:10 [INFO]         'inputs': [\n",
      "2024-05-29 18:36:10 [INFO]         ],\n",
      "2024-05-29 18:36:10 [INFO]         'model_name': '',\n",
      "2024-05-29 18:36:10 [INFO]         'ni_workload_name': 'quantization',\n",
      "2024-05-29 18:36:10 [INFO]         'op_name_dict': {\n",
      "2024-05-29 18:36:10 [INFO]             '.*lm_head': {\n",
      "2024-05-29 18:36:10 [INFO]                 'weight': {\n",
      "2024-05-29 18:36:10 [INFO]                     'dtype': [\n",
      "2024-05-29 18:36:10 [INFO]                         'fp32'\n",
      "2024-05-29 18:36:10 [INFO]                     ]\n",
      "2024-05-29 18:36:10 [INFO]                 }\n",
      "2024-05-29 18:36:10 [INFO]             },\n",
      "2024-05-29 18:36:10 [INFO]             '.*output_layer': {\n",
      "2024-05-29 18:36:10 [INFO]                 'weight': {\n",
      "2024-05-29 18:36:10 [INFO]                     'dtype': [\n",
      "2024-05-29 18:36:10 [INFO]                         'fp32'\n",
      "2024-05-29 18:36:10 [INFO]                     ]\n",
      "2024-05-29 18:36:10 [INFO]                 }\n",
      "2024-05-29 18:36:10 [INFO]             },\n",
      "2024-05-29 18:36:10 [INFO]             '.*embed_out': {\n",
      "2024-05-29 18:36:10 [INFO]                 'weight': {\n",
      "2024-05-29 18:36:10 [INFO]                     'dtype': [\n",
      "2024-05-29 18:36:10 [INFO]                         'fp32'\n",
      "2024-05-29 18:36:10 [INFO]                     ]\n",
      "2024-05-29 18:36:10 [INFO]                 }\n",
      "2024-05-29 18:36:10 [INFO]             }\n",
      "2024-05-29 18:36:10 [INFO]         },\n",
      "2024-05-29 18:36:10 [INFO]         'op_type_dict': {\n",
      "2024-05-29 18:36:10 [INFO]             '.*': {\n",
      "2024-05-29 18:36:10 [INFO]                 'weight': {\n",
      "2024-05-29 18:36:10 [INFO]                     'bits': [\n",
      "2024-05-29 18:36:10 [INFO]                         4\n",
      "2024-05-29 18:36:10 [INFO]                     ],\n",
      "2024-05-29 18:36:10 [INFO]                     'dtype': [\n",
      "2024-05-29 18:36:10 [INFO]                         'int4'\n",
      "2024-05-29 18:36:10 [INFO]                     ],\n",
      "2024-05-29 18:36:10 [INFO]                     'group_size': [\n",
      "2024-05-29 18:36:10 [INFO]                         32\n",
      "2024-05-29 18:36:10 [INFO]                     ],\n",
      "2024-05-29 18:36:10 [INFO]                     'scheme': [\n",
      "2024-05-29 18:36:10 [INFO]                         'sym'\n",
      "2024-05-29 18:36:10 [INFO]                     ],\n",
      "2024-05-29 18:36:10 [INFO]                     'algorithm': [\n",
      "2024-05-29 18:36:10 [INFO]                         'RTN'\n",
      "2024-05-29 18:36:10 [INFO]                     ]\n",
      "2024-05-29 18:36:10 [INFO]                 }\n",
      "2024-05-29 18:36:10 [INFO]             }\n",
      "2024-05-29 18:36:10 [INFO]         },\n",
      "2024-05-29 18:36:10 [INFO]         'outputs': [\n",
      "2024-05-29 18:36:10 [INFO]         ],\n",
      "2024-05-29 18:36:10 [INFO]         'quant_format': 'default',\n",
      "2024-05-29 18:36:10 [INFO]         'quant_level': 'auto',\n",
      "2024-05-29 18:36:10 [INFO]         'recipes': {\n",
      "2024-05-29 18:36:10 [INFO]             'smooth_quant': False,\n",
      "2024-05-29 18:36:10 [INFO]             'smooth_quant_args': {\n",
      "2024-05-29 18:36:10 [INFO]             },\n",
      "2024-05-29 18:36:10 [INFO]             'layer_wise_quant': False,\n",
      "2024-05-29 18:36:10 [INFO]             'layer_wise_quant_args': {\n",
      "2024-05-29 18:36:10 [INFO]             },\n",
      "2024-05-29 18:36:10 [INFO]             'fast_bias_correction': False,\n",
      "2024-05-29 18:36:10 [INFO]             'weight_correction': False,\n",
      "2024-05-29 18:36:10 [INFO]             'gemm_to_matmul': True,\n",
      "2024-05-29 18:36:10 [INFO]             'graph_optimization_level': None,\n",
      "2024-05-29 18:36:10 [INFO]             'first_conv_or_matmul_quantization': True,\n",
      "2024-05-29 18:36:10 [INFO]             'last_conv_or_matmul_quantization': True,\n",
      "2024-05-29 18:36:10 [INFO]             'pre_post_process_quantization': True,\n",
      "2024-05-29 18:36:10 [INFO]             'add_qdq_pair_to_weight': False,\n",
      "2024-05-29 18:36:10 [INFO]             'optypes_to_exclude_output_quant': [\n",
      "2024-05-29 18:36:10 [INFO]             ],\n",
      "2024-05-29 18:36:10 [INFO]             'dedicated_qdq_pair': False,\n",
      "2024-05-29 18:36:10 [INFO]             'rtn_args': {\n",
      "2024-05-29 18:36:10 [INFO]                 'enable_full_range': True,\n",
      "2024-05-29 18:36:10 [INFO]                 'enable_mse_search': False\n",
      "2024-05-29 18:36:10 [INFO]             },\n",
      "2024-05-29 18:36:10 [INFO]             'awq_args': {\n",
      "2024-05-29 18:36:10 [INFO]             },\n",
      "2024-05-29 18:36:10 [INFO]             'gptq_args': {\n",
      "2024-05-29 18:36:10 [INFO]             },\n",
      "2024-05-29 18:36:10 [INFO]             'teq_args': {\n",
      "2024-05-29 18:36:10 [INFO]             },\n",
      "2024-05-29 18:36:10 [INFO]             'autoround_args': {\n",
      "2024-05-29 18:36:10 [INFO]             }\n",
      "2024-05-29 18:36:10 [INFO]         },\n",
      "2024-05-29 18:36:10 [INFO]         'reduce_range': None,\n",
      "2024-05-29 18:36:10 [INFO]         'TuningCriterion': {\n",
      "2024-05-29 18:36:10 [INFO]             'max_trials': 100,\n",
      "2024-05-29 18:36:10 [INFO]             'objective': [\n",
      "2024-05-29 18:36:10 [INFO]                 'performance'\n",
      "2024-05-29 18:36:10 [INFO]             ],\n",
      "2024-05-29 18:36:10 [INFO]             'strategy': 'basic',\n",
      "2024-05-29 18:36:10 [INFO]             'strategy_kwargs': None,\n",
      "2024-05-29 18:36:10 [INFO]             'timeout': 0\n",
      "2024-05-29 18:36:10 [INFO]         },\n",
      "2024-05-29 18:36:10 [INFO]         'use_bf16': True\n",
      "2024-05-29 18:36:10 [INFO]     }\n",
      "2024-05-29 18:36:10 [INFO] }\n",
      "2024-05-29 18:36:10 [WARNING] [Strategy] Please install `mpi4py` correctly if using distributed tuning; otherwise, ignore this warning.\n",
      "2024-05-29 18:36:10 [INFO] Pass query framework capability elapsed time: 2.69 ms\n",
      "2024-05-29 18:36:10 [INFO] Do not evaluate the baseline and quantize the model with default configuration.\n",
      "2024-05-29 18:36:10 [INFO] Quantize the model with default config.\n",
      "2024-05-29 18:36:10 [INFO] All algorithms to do: {'RTN'}\n",
      "2024-05-29 18:36:10 [INFO] quantizing with the round-to-nearest algorithm\n",
      "2024-05-29 18:36:49 [INFO] |******Mixed Precision Statistics******|\n",
      "2024-05-29 18:36:49 [INFO] +---------+-------+-----------+--------+\n",
      "2024-05-29 18:36:49 [INFO] | Op Type | Total |  A32W4G32 |  FP32  |\n",
      "2024-05-29 18:36:49 [INFO] +---------+-------+-----------+--------+\n",
      "2024-05-29 18:36:49 [INFO] |  Linear |  113  |    112    |   1    |\n",
      "2024-05-29 18:36:49 [INFO] +---------+-------+-----------+--------+\n",
      "2024-05-29 18:36:49 [INFO] Pass quantize model elapsed time: 38531.07 ms\n",
      "2024-05-29 18:36:49 [INFO] Save tuning history to /mnt/workspace/nc_workspace/2024-05-29_18-02-05/./history.snapshot.\n",
      "2024-05-29 18:36:49 [INFO] [Strategy] Found the model meets accuracy requirements, ending the tuning process.\n",
      "2024-05-29 18:36:49 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
      "2024-05-29 18:36:49 [INFO] Save deploy yaml to /mnt/workspace/nc_workspace/2024-05-29_18-02-05/deploy.yaml\n",
      "2024-05-29 18:41:44 [INFO] WeightOnlyQuant done.\n",
      "2024-05-29 18:41:44,977 - root - INFO - Optimized Model loaded.\n"
     ]
    }
   ],
   "source": [
    "from intel_extension_for_transformers.neural_chat import PipelineConfig \n",
    "from intel_extension_for_transformers.neural_chat import build_chatbot \n",
    "from intel_extension_for_transformers.neural_chat import plugins \n",
    "from intel_extension_for_transformers.transformers import RtnConfig \n",
    "\n",
    "plugins.retrieval.enable=True \n",
    "plugins.retrieval.args['embedding_model'] = \"./bge-base-zh-v1.5\" \n",
    "plugins.retrieval.args[\"input_path\"]=\"./sample.jsonl\" \n",
    "config = PipelineConfig(model_name_or_path='./chatglm3-6b', plugins=plugins, optimization_config=RtnConfig(compute_dtype=\"int8\", weight_dtype=\"int4_fullrange\")) \n",
    "\n",
    "chatbot = build_chatbot(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc277780-e074-47c8-8361-09695e543ace",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-29T10:43:01.282623Z",
     "iopub.status.busy": "2024-05-29T10:43:01.282215Z",
     "iopub.status.idle": "2024-05-29T10:43:37.023188Z",
     "shell.execute_reply": "2024-05-29T10:43:37.022610Z",
     "shell.execute_reply.started": "2024-05-29T10:43:01.282597Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnvrg.io网站是由一个名为CNVRG的神秘组织创建的。关于这个组织的具体信息很难获取，因为它们使用了多种手段来保持匿名。然而，根据网站上发布的信息，可以推测出该组织可能与网络安全和虚拟现实技术有关。\n"
     ]
    }
   ],
   "source": [
    "plugins.retrieval.enable=False # disable retrieval \n",
    "response = chatbot.predict(query=\"cnvrg.io网站是由谁创建的？\") \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53f4de0c-97c2-4011-a608-58f58994c4e3",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-29T10:51:47.410715Z",
     "iopub.status.busy": "2024-05-29T10:51:47.410365Z",
     "iopub.status.idle": "2024-05-29T10:52:39.934753Z",
     "shell.execute_reply": "2024-05-29T10:52:39.934201Z",
     "shell.execute_reply.started": "2024-05-29T10:51:47.410694Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7909c8a9d59241ebb021b33a3107a144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 18:52:16,605 - root - INFO - Chat with QA Agent.\n",
      "/opt/conda/envs/itrex/lib/python3.10/site-packages/torch/amp/autocast_mode.py:267: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
      "CPU Autocast only supports dtype of torch.bfloat16, torch.float16 currently.\n",
      "  warnings.warn(error_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnvrg.io网站由Yochay Ettun和Leah Forkosh Kolben创建。\n"
     ]
    }
   ],
   "source": [
    "plugins.retrieval.enable=True # enable retrieval \n",
    "response = chatbot.predict(query=\"cnvrg.io网站是由谁创建的？\") \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49157e80-0ac0-4d30-b332-508c8af8c7e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T10:54:31.543697Z",
     "iopub.status.busy": "2024-05-29T10:54:31.543344Z",
     "iopub.status.idle": "2024-05-29T10:55:15.617383Z",
     "shell.execute_reply": "2024-05-29T10:55:15.616816Z",
     "shell.execute_reply.started": "2024-05-29T10:54:31.543676Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798b41bbf710477f9a70c16a12264ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 18:55:01,141 - root - INFO - Chat with QA Agent.\n",
      "/opt/conda/envs/itrex/lib/python3.10/site-packages/torch/amp/autocast_mode.py:267: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
      "CPU Autocast only supports dtype of torch.bfloat16, torch.float16 currently.\n",
      "  warnings.warn(error_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您的QQ密码是tytyty00999。\n"
     ]
    }
   ],
   "source": [
    "plugins.retrieval.enable=True # enable retrieval \n",
    "response = chatbot.predict(query=\"我的QQ密码是？\") \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df02fa54-0d1e-4b7a-be34-465425c444e6",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-05-29T10:56:35.084549Z",
     "iopub.status.busy": "2024-05-29T10:56:35.084102Z",
     "iopub.status.idle": "2024-05-29T10:56:48.003730Z",
     "shell.execute_reply": "2024-05-29T10:56:48.003099Z",
     "shell.execute_reply.started": "2024-05-29T10:56:35.084513Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "很抱歉，作为人工智能助手，我无法获取您的个人信息。请您自行设置或找回密码。\n"
     ]
    }
   ],
   "source": [
    "plugins.retrieval.enable=False # enable retrieval \n",
    "response = chatbot.predict(query=\"我的QQ密码是？\") \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e299877e-29f0-416c-948e-8d04085900d5",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-29T11:42:36.987950Z",
     "iopub.status.busy": "2024-05-29T11:42:36.987598Z",
     "iopub.status.idle": "2024-05-29T11:42:44.970799Z",
     "shell.execute_reply": "2024-05-29T11:42:44.970241Z",
     "shell.execute_reply.started": "2024-05-29T11:42:36.987929Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "咖啡店现在有13个苹果。\n"
     ]
    }
   ],
   "source": [
    "query = \"咖啡店有23个苹果，如果它们用了20个做了一顿午饭，又买了6个新的苹果，现在他们总共有多少个苹果？\"\n",
    "response = chatbot.predict(query) \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40a2c989-f1c5-491b-9d65-adb8f22920b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T11:44:15.558056Z",
     "iopub.status.busy": "2024-05-29T11:44:15.557702Z",
     "iopub.status.idle": "2024-05-29T11:44:54.829361Z",
     "shell.execute_reply": "2024-05-29T11:44:54.828789Z",
     "shell.execute_reply.started": "2024-05-29T11:44:15.558035Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "首先，咖啡店开始时有23个苹果。  \n",
      "然后，他们用掉了20个苹果，所以剩下的苹果数量是23-20=3个。  \n",
      "接着，他们又买了6个新的苹果，所以现在总共有3+6=9个苹果。\n"
     ]
    }
   ],
   "source": [
    "query = \"咖啡店有23个苹果，如果它们用了20个做了一顿午饭，又买了6个新的苹果，现在他们总共有多少个苹果？请一步步进行推理，并输出每一步的分析结果。\"\n",
    "response = chatbot.predict(query) \n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itrex",
   "language": "python",
   "name": "itrex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
